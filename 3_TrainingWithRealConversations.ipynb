{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_TrainingWithRealConversations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sishef/nlpworkshop/blob/pilot-updates/3_TrainingWithRealConversations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook 3: Training With Real Conversations"
      ],
      "metadata": {
        "id": "0fDg5SFlBd4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's hopefully becoming clear that it'd be impractical to hard-code our chatbot to respond to any input which a user could throw at it.\n",
        "\n",
        "Thankfully, there are other ways - in this session, we'll take a **corpus** (large structured body of text) of historical conversations, and use it to select responses to user input. This means our bot can learn from real conversations, rather than relying on every conversation path included in our code."
      ],
      "metadata": {
        "id": "zKX0CveDBdbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCjAYYftbTw6"
      },
      "outputs": [],
      "source": [
        "# This workshop uses chatterbot-corpus, a library which contains a corpus of conversations in YAML format\n",
        "# You can view these raw files in the chatterbot-corpus GitHub repo: https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/english"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import yaml\n",
        "import inspect\n",
        "import os"
      ],
      "metadata": {
        "id": "yTEJ9BsHcvnF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a fairly simple approach, we will take all of these historical conversations, and build a lookup table of known inputs and replies."
      ],
      "metadata": {
        "id": "Hdhq_cd0KV03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dict of msg->response from the files in the corpus\n",
        "# Returns list of conversations\n",
        "def load_chatterbot_conversations_simple():\n",
        "  data_files = [\n",
        "      'ai.yml',\n",
        "      'botprofile.yml',\n",
        "      'computers.yml',\n",
        "      #'conversations.yml',\n",
        "      'emotion.yml',\n",
        "      'food.yml',\n",
        "      'gossip.yml',\n",
        "      'greetings.yml',\n",
        "      'health.yml',\n",
        "      'history.yml',\n",
        "      'humor.yml',\n",
        "      'literature.yml',\n",
        "      'money.yml',\n",
        "      'movies.yml',\n",
        "      'politics.yml',\n",
        "      'psychology.yml',\n",
        "      'science.yml',\n",
        "      'sports.yml',\n",
        "      'trivia.yml'\n",
        "  ]\n",
        "\n",
        "  chatterbot_base_url = 'https://raw.githubusercontent.com/gunthercox/chatterbot-corpus/master/chatterbot_corpus/data/english/'\n",
        "  conversations = []\n",
        "  for data_file in data_files:\n",
        "    resp = requests.get(chatterbot_base_url + data_file)\n",
        "    if resp.status_code != 200:\n",
        "      print('Issue fetching {} - skipping'.format(data_file))\n",
        "    conversations = conversations + yaml.load(resp.content, Loader=yaml.FullLoader)['conversations']\n",
        "  lookup = {}\n",
        "  for convo in conversations:\n",
        "    lookup[convo.pop(0)] = convo\n",
        "  return lookup\n",
        "\n",
        "\n",
        "lookup = load_chatterbot_conversations_simple()"
      ],
      "metadata": {
        "id": "1BRTVhNTdnar"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this ```lookup``` dictionary we can look up an input message in the dictionary to find the corresponding responses, based on the message history loaded."
      ],
      "metadata": {
        "id": "VEtXziLQvjs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['What language are you written in?']"
      ],
      "metadata": {
        "id": "hMniokQwrtbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f478c3d3-7193-4ce3-a656-d90d87308223"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am written in Python.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['What is a computer?']"
      ],
      "metadata": {
        "id": "UcUIHYDCEhqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this will fail if we look up a message which isn't in the history."
      ],
      "metadata": {
        "id": "SaQy1DS1vzNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['How are you today?']"
      ],
      "metadata": {
        "id": "7RReJozMv2Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like before, we have the issue that we're case-sensitive and punctuation sensitive."
      ],
      "metadata": {
        "id": "g5SdR9lx8Mih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['what is a computer']"
      ],
      "metadata": {
        "id": "VtPhMdM_G2Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can handle this by normalizing the questions in the conversation history as we load them, and normalizing the user's input before we look it up."
      ],
      "metadata": {
        "id": "W-VcgJGIG2sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(msg):\n",
        "  msg = msg.lower()\n",
        "  symbols = ['?','-',',',':',';']\n",
        "  for symbol in symbols:\n",
        "    msg = msg.replace(symbol, '')\n",
        "  return msg"
      ],
      "metadata": {
        "id": "nokIvv8zGRbH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dict of msg->response from the files in the corpus\n",
        "def load_chatterbot_conversations():\n",
        "  data_files = [\n",
        "      'ai.yml',\n",
        "      'botprofile.yml',\n",
        "      'computers.yml',\n",
        "      #'conversations.yml',\n",
        "      'emotion.yml',\n",
        "      'food.yml',\n",
        "      'gossip.yml',\n",
        "      'greetings.yml',\n",
        "      'health.yml',\n",
        "      'history.yml',\n",
        "      'humor.yml',\n",
        "      'literature.yml',\n",
        "      'money.yml',\n",
        "      'movies.yml',\n",
        "      'politics.yml',\n",
        "      'psychology.yml',\n",
        "      'science.yml',\n",
        "      'sports.yml',\n",
        "      'trivia.yml'\n",
        "  ]\n",
        "\n",
        "  chatterbot_base_url = 'https://raw.githubusercontent.com/gunthercox/chatterbot-corpus/master/chatterbot_corpus/data/english/'\n",
        "  conversations = []\n",
        "  for data_file in data_files:\n",
        "    resp = requests.get(chatterbot_base_url + data_file)\n",
        "    if resp.status_code != 200:\n",
        "      print('Issue fetching {} - skipping'.format(data_file))\n",
        "    conversations = conversations + yaml.load(resp.content, Loader=yaml.FullLoader)['conversations']\n",
        "  lookup = {}\n",
        "  for convo in conversations:\n",
        "    lookup[normalize_text(convo.pop(0))] = convo\n",
        "  return lookup\n",
        "\n",
        "\n",
        "lookup = load_chatterbot_conversations()"
      ],
      "metadata": {
        "id": "Ea90YeiWGhmQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['what is a computer']"
      ],
      "metadata": {
        "id": "2E6xS_tkGn8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6179657-f445-4b9d-a56c-179ada1e89e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output.',\n",
              " \"The thing you're using to talk to me is a computer.\",\n",
              " 'An electronic device capable of performing calculations at very high speed and with very high accuracy.',\n",
              " 'A device which maps one set of numbers onto another set of numbers.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or, using normalized user input:"
      ],
      "metadata": {
        "id": "Glm4wd4HHIoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup[normalize_text(input(''))]"
      ],
      "metadata": {
        "id": "RSW7rS3nG_jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Replies\n",
        "\n",
        "You'll notice that the dictionary contains lists of responses, rather than just one response per input. Obviously, returning this list to the user would look strange.\n",
        "\n",
        "A naive solution would be to return the first item in the list:"
      ],
      "metadata": {
        "id": "QesyEXI0HmLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup['what is a computer'][0]"
      ],
      "metadata": {
        "id": "_TUS17MPH92v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "58ad78ad-b920-4a4b-a041-7381f0ed38dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This would work, but it means that many of our responses would never be seen. We can make the chatbot a little less predictable (and seem a little more alive) by randomly choosing one of the suitable responses:"
      ],
      "metadata": {
        "id": "pwuuee2PIBBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "LYXxSl1aITIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_response(msg):\n",
        "  try:\n",
        "\n",
        "    # Fetch the list of possible responses\n",
        "    options = lookup[normalize_text(msg)]\n",
        "    # Return a randomly selected item from the list (using the Python random library)\n",
        "    return random.choice(options)\n",
        "\n",
        "  # Handle the case where the input isn't in the dictionary\n",
        "  except KeyError:\n",
        "    return 'No suitable answers found.'"
      ],
      "metadata": {
        "id": "oha-EwgwIUAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choose_response('What is a computer?')"
      ],
      "metadata": {
        "id": "oEuJJ-X1I8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run the above cell multiple times, you'll get different response. \n",
        "\n",
        "In computer science terms, functions like this (where the output depends on a random element, giving one of many potential from an input) are described as **non-deterministic**."
      ],
      "metadata": {
        "id": "CDqJkyr8I-Lg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK:**\n",
        "* Modify your chatbot to give a randomized reply from this training data. \n",
        "* If the user's input isn't in the corpus, the bot should reply using your existing logic. \n",
        "* Ensure that your chemical symbol question still works."
      ],
      "metadata": {
        "id": "sLVOJt2bJny_"
      }
    }
  ]
}